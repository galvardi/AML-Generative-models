
from tqdm import trange
import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torch.utils.data import Dataset
from mingpt_repo.mingpt.bpe import BPETokenizer
from mingpt_repo.mingpt.model import GPT
from mingpt_repo.mingpt.trainer import Trainer


WORKERS = 2
ITERATIONS = 2500
BATCH_SIZE = 32
LEARNING_RATE = 5e-4
BLOCK_SIZE = 64
ORG_VOCAB_SIZE = 50257
MODEL_NAME = 'gpt2'
TEXT_PATH = "alice_in_wonderland.txt"


class TokenDataset(Dataset):

    def __init__(self,data, labels):
        self.dataset = data
        self.labels = labels

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        return self.dataset[idx], self.labels[idx] # unpack


def seperate_data(data):
    i = 0
    # data = torch.tensor(data)
    dataset = []
    labels = []
    while i < len(data) - BLOCK_SIZE:
        dataset.append(data[i:i+BLOCK_SIZE])
        labels.append(data[i+1:i+1+BLOCK_SIZE])
        i += 1
    return dataset, labels


def log_loss(loss):
        running_loss.append(round(trainer.loss.item(),3))

def init_model_and_trainer(train_dataset):
    model_config = GPT.get_default_config()
    model_config.model_type = MODEL_NAME
    model_config.vocab_size = ORG_VOCAB_SIZE  # openai's model vocabulary
    model_config.block_size = BLOCK_SIZE  # our model BLOCK_SIZE
    model = GPT(model_config)

    train_config = Trainer.get_default_config()
    train_config.learning_rate = LEARNING_RATE  # many possible options, see the file
    train_config.max_iters = ITERATIONS
    train_config.batch_size = BATCH_SIZE
    train_config.num_workers = WORKERS
    trainer = Trainer(train_config, model, train_dataset)

    return model, trainer


def inversion_training(model, inversion_target, embd_dim, seq_dim,
                       iterations=1000):
    inp_vec = torch.rand(1, seq_dim, embd_dim, requires_grad=True,
                         device=device)
    optimizer = torch.optim.Adam([inp_vec],lr=1e-2)
    model.to(device)
    inversion_sentence = [t.to(device) for t in inversion_target]
    running_loss = []
    for _ in trange(iterations):
        optimizer.zero_grad()
        logits, _ = model(None, inversion_vec=inp_vec)
        logits = logits[-1, :, :]
        loss = F.cross_entropy(logits, inversion_sentence[0])
        running_loss.append(loss)
        loss.backward()
        optimizer.step()
    return inp_vec, running_loss

# this function was generated by chatgpt with slight changes by me
def colorize_strings(strings, weights):
    # Normalize weights between 0 and 1
    normalized_weights = (np.array(weights) - np.min(weights)) / (
                np.max(weights) - np.min(weights))

    colored_string = ""
    for string, weight in zip(strings, normalized_weights):
        # Calculate RGB color based on weight
        color = (1 - weight, weight,
                 0)  # Higher weight: greener, lower weight: redder

        # Append the string with the colored version
        colored_string += "\033[48;2;{};{};{}m{}\033[0m".format(
            int(color[0] * 255), int(color[1] * 255), int(color[2] * 255),
            string + " "
        )

    return colored_string.strip()


def infer_atttention_choice_by_block(sent_tok, block_idx):
    generated_sent = model.generate(sent_tok, max_new_tokens=2)
    attention_blk = model.view_block(block_idx)
    blk_mean_score = attention_blk.get_attention_score().mean(dim=1)[0]
    word_attn = blk_mean_score[-1]
    word_attn = [round(word_attn[i].item(), 3) for i in range(
        word_attn.shape[0])]
    sent = bpe.decode(generated_sent[0]).split(" ")
    print(colorize_strings(sent[:-1], word_attn))
    print(word_attn)

if __name__ == '__main__':

    trained = False


    with open(TEXT_PATH, 'r') as f:
        text = f.read()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    bpe = BPETokenizer()
    tok_data = bpe(text)
    train_dataset = TokenDataset(*seperate_data(tok_data[0]))
    model, trainer = init_model_and_trainer(train_dataset)

    # Q1

    if not trained:
        running_loss = []
        iterations = [0]
        trainer.set_callback("on_batch_end", log_loss)
        trainer.run()
        # torch.save(model.state_dict(), "model_weights.pth")
        plt.plot(torch.arange(ITERATIONS), running_loss)
        plt.title("GPT2 Training Loss")
        plt.xlabel("iteration")
        plt.ylabel("loss")
        plt.show()
    else:
        # model.load_state_dict(torch.load("weights/model_weights.pth",
        #                                  map_location=device))
        pass

    # Q2
    model.eval()
    for param in model.parameters():
        param.requires_grad = False

    target_sent = "I am a little squirrel holding a walnut"
    target_tok = bpe(target_sent)
    target_tok.to(device)

    inversion_iter = 1000

    inp_vec, inversion_loss = inversion_training(model, target_tok, 768, len(target_tok[0]),
                                      iterations=inversion_iter)
    logits, _ = model(None, inversion_vec=inp_vec)
    logits = logits[0, :, :]
    softmaxed_logits = F.softmax(logits, dim=-1)
    _, tokens = torch.topk(softmaxed_logits, k=1, dim=-1)
    inverted_sent = [bpe.decode(t) for t in tokens]
    print(inverted_sent)
    loss = [inversion_loss[i].detach() for i in range(len(inversion_loss))]
    plt.plot(list(range(inversion_iter)), loss)
    plt.title("Inversion Loss")
    plt.xlabel("iteration")
    plt.ylabel("loss")
    plt.show()


    # Q3
    sent_tok = bpe("With Jake the Dog and Finn the Human The fun")
    print("Attention by last block:")
    infer_atttention_choice_by_block(sent_tok, -1)
    print()

    # Q4
    print("Attention by first block:")
    infer_atttention_choice_by_block(sent_tok, 0)

    # Q5
    sent, probs = model.generate(bpe("Dogs are mans best"),
                                 max_new_tokens=4,probabilites=True)
    dec_sent = bpe.decode(sent[0])
    log_prob = torch.prod(torch.log(probs[0]))

    print(f"log probability of '{dec_sent}' is : {log_prob.item()}")
